{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T10:15:19.145522Z",
     "start_time": "2024-04-27T10:15:19.128410Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"openai.env\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# agent使用入门",
   "id": "e376e9b3743d47af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:16:09.296697Z",
     "start_time": "2024-04-27T10:15:58.755626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import create_openai_functions_agent  #不同的agent有不同的创建方式\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "#创建LLM \n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "#定义agent的prompt:可以自己编写,也可以从hub拉取\n",
    "#https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "#定义工具,加载预制的工具,注意有的工具需要提供LLM\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "#创建agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "#定义agent的执行器，这里注意与老版本的不同\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"你好\"})"
   ],
   "id": "5d6922ad7a55bec4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你好！有什么我可以帮助你的吗？\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好', 'output': '你好！有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 自定义tool+ 使用系统tool",
   "id": "261624771d065f59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 自定义tool",
   "id": "e51954bd4a670ea1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:34:16.837170Z",
     "start_time": "2024-04-27T10:34:16.793159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "import os\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"32109af1224c43d11768866970c41e4e681e03bf220c7bd2b9a16af817431719\"\n",
    "\n",
    "\n",
    "#使用注解@tool即可将一个方法变成工具\n",
    "#方法第一行是tools的使用描述\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"当需要查找实时信息的时候才会使用这个工具.\"\"\"\n",
    "    serp = SerpAPIWrapper()\n",
    "    return serp.run(query)\n",
    "\n"
   ],
   "id": "cd63d6506486702d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:34:21.332745Z",
     "start_time": "2024-04-27T10:34:17.744224Z"
    }
   },
   "cell_type": "code",
   "source": "search(\"北京今天的天气如何?\")",
   "id": "56f0e9b41041118c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'type': 'weather_result', 'temperature': '72', 'unit': 'Fahrenheit', 'precipitation': '20%', 'humidity': '55%', 'wind': '4 mph', 'location': '中国北京市', 'date': 'Saturday', 'weather': 'Cloudy'}\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 调用系统tool - create_retriever_tool",
   "id": "6052165a7ba808c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:36:10.638265Z",
     "start_time": "2024-04-27T10:36:07.150507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#RAG增强生成\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 会把该网页内容拿下来存储到向量数据库中\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()\n",
    "#搜索匹配文档块\n",
    "retriever.invoke(\"如何debug?\")[0]"
   ],
   "id": "85b7eaab6da486d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Oftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set‚ÄãWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.', 'language': 'en'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:36:51.671419Z",
     "start_time": "2024-04-27T10:36:51.666519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#把检索器加入到工具中\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"langsmith_search\",\n",
    "    description=\"搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！\",\n",
    ")\n",
    "retriever_tool"
   ],
   "id": "ac88a8125567e749",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith_search', description='搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x117c7c180>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12750b1d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x117c7c220>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12750b1d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:37:06.017553Z",
     "start_time": "2024-04-27T10:37:06.012619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#可用工具集\n",
    "tools = [search, retriever_tool]\n",
    "tools"
   ],
   "id": "9933a2e32d69bb62",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='search', description='search(query: str) -> str - 当需要查找实时信息的时候才会使用这个工具.', args_schema=<class 'pydantic.main.searchSchema'>, func=<function search at 0x127df31a0>),\n",
       " Tool(name='langsmith_search', description='搜索有关 LangSmith 的信息。关于LangSmith的任何问题，你一定要使用这个工具！', args_schema=<class 'langchain.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x117c7c180>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12750b1d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x117c7c220>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x12750b1d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## agent带哦用",
   "id": "658d9263c2d09d21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:38:01.090519Z",
     "start_time": "2024-04-27T10:37:56.052278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#从hub中获取模版\n",
    "from langchain import hub\n",
    "#创建agent\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "#创建agent执行器AgentExecutor\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "#配置模型\n",
    "model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
    "# 一个最简单的模版,带记忆\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "id": "a4bb79d4fbfe52f6",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:38:08.273576Z",
     "start_time": "2024-04-27T10:38:02.937755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#执行\n",
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ],
   "id": "531e6cb7b0ecf0b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:39:05.115414Z",
     "start_time": "2024-04-27T10:38:12.516778Z"
    }
   },
   "cell_type": "code",
   "source": "agent_executor.invoke({\"input\": \"langsmith如何帮助做项目测试?\"})",
   "id": "7a0f7fb306931208",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': '如何帮助做项目测试'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mEvery playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing‚ÄãBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it‚Äôs important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it‚Äôs breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback‚ÄãWhen launching your application to an initial set of users, it‚Äôs important to gather human feedback on the responses it‚Äôs producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up\n",
      "\n",
      "These test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View‚ÄãWhen prototyping different versions of your applications and making changes, it‚Äôs important to see whether or not you‚Äôve regressed with respect to your initial test cases.\n",
      "Oftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\n",
      "In order to get a sense for which variant is performing better, it‚Äôs useful to be able to view results for different configurations on the same datapoints side-by-side. We‚Äôve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground‚ÄãLangSmith provides a playground environment for rapid iteration and experimentation.\n",
      "\n",
      "to a Dataset‚ÄãAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production‚ÄãClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you‚Äôll also want to do once your app hits production.However, especially at the production stage, it‚Äôs crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near\n",
      "\n",
      "Oftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\n",
      "We provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set‚ÄãWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\u001B[0m\u001B[32;1m\u001B[1;3mLangSmith提供了一系列的工具和功能来帮助进行项目测试：\n",
      "\n",
      "1. **日志记录**：每次在playground运行的日志都会被系统记录下来，这些日志可以用来创建测试用例或与其他运行进行比较。\n",
      "\n",
      "2. **Beta测试**：Beta测试允许开发者在真实世界的场景中收集他们的LLM应用程序的性能数据。在这个阶段，理解应用在哪些输入上表现良好或不良，以及在哪些情况下出现问题是非常重要的。反馈收集和运行注释对于这个工作流程至关重要。这将有助于策划测试用例，帮助跟踪回归/改进和开发自动评估。\n",
      "\n",
      "3. **反馈收集**：在向初始用户群发布应用程序时，收集人类对其产生的反应的反馈是非常重要的。这有助于引起对最有趣运行的关注，并突出导致问题反应的边缘案例。LangSmith允许你将反馈分数附加到记录的追踪中。\n",
      "\n",
      "4. **比较视图**：在原型化你的应用程序的不同版本并进行更改时，看看你是否在初始测试用例上有所回归是非常重要的。在提示、检索策略或模型选择的变化可能会对应用程序产生的反应产生巨大影响。为了得到哪个变体表现更好的感觉，能够在同一数据点上查看不同配置的结果是非常有用的。我们在测试运行的比较视图上投入了大量的精力，以便跟踪和诊断在应用程序的多个修订版中的测试分数的回归。\n",
      "\n",
      "5. **Playground**：LangSmith提供了一个playground环境，用于快速迭代和实验。\n",
      "\n",
      "6. **数据集**：在应用程序进入beta测试阶段时，继续收集数据以精炼和提高其性能是至关重要的。LangSmith允许你将运行作为示例添加到数据集中，扩大你在真实世界场景中的测试覆盖范围。\n",
      "\n",
      "7. **生产**：在应用程序进入生产阶段时，仔细检查关键数据点，增长基准数据集，注释追踪，深入重要数据的追踪视图是你也想做的工作流程。然而，尤其是在生产阶段，获取应用程序性能的高级概述，包括延迟、成本和反馈分数，是至关重要的。这确保了它在大规模下提供了理想的结果。\n",
      "\n",
      "8. **初始测试集**：LangSmith允许开发者创建数据集，这些数据集是输入和参考输出的集合，并使用这些来对他们的LLM应用程序进行测试。\n",
      "\n",
      "总的来说，LangSmith提供了一套完整的工具和功能，帮助开发者在项目测试中更有效地进行问题定位、性能评估和反馈收集。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'langsmith如何帮助做项目测试?',\n",
       " 'output': 'LangSmith提供了一系列的工具和功能来帮助进行项目测试：\\n\\n1. **日志记录**：每次在playground运行的日志都会被系统记录下来，这些日志可以用来创建测试用例或与其他运行进行比较。\\n\\n2. **Beta测试**：Beta测试允许开发者在真实世界的场景中收集他们的LLM应用程序的性能数据。在这个阶段，理解应用在哪些输入上表现良好或不良，以及在哪些情况下出现问题是非常重要的。反馈收集和运行注释对于这个工作流程至关重要。这将有助于策划测试用例，帮助跟踪回归/改进和开发自动评估。\\n\\n3. **反馈收集**：在向初始用户群发布应用程序时，收集人类对其产生的反应的反馈是非常重要的。这有助于引起对最有趣运行的关注，并突出导致问题反应的边缘案例。LangSmith允许你将反馈分数附加到记录的追踪中。\\n\\n4. **比较视图**：在原型化你的应用程序的不同版本并进行更改时，看看你是否在初始测试用例上有所回归是非常重要的。在提示、检索策略或模型选择的变化可能会对应用程序产生的反应产生巨大影响。为了得到哪个变体表现更好的感觉，能够在同一数据点上查看不同配置的结果是非常有用的。我们在测试运行的比较视图上投入了大量的精力，以便跟踪和诊断在应用程序的多个修订版中的测试分数的回归。\\n\\n5. **Playground**：LangSmith提供了一个playground环境，用于快速迭代和实验。\\n\\n6. **数据集**：在应用程序进入beta测试阶段时，继续收集数据以精炼和提高其性能是至关重要的。LangSmith允许你将运行作为示例添加到数据集中，扩大你在真实世界场景中的测试覆盖范围。\\n\\n7. **生产**：在应用程序进入生产阶段时，仔细检查关键数据点，增长基准数据集，注释追踪，深入重要数据的追踪视图是你也想做的工作流程。然而，尤其是在生产阶段，获取应用程序性能的高级概述，包括延迟、成本和反馈分数，是至关重要的。这确保了它在大规模下提供了理想的结果。\\n\\n8. **初始测试集**：LangSmith允许开发者创建数据集，这些数据集是输入和参考输出的集合，并使用这些来对他们的LLM应用程序进行测试。\\n\\n总的来说，LangSmith提供了一套完整的工具和功能，帮助开发者在项目测试中更有效地进行问题定位、性能评估和反馈收集。'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:39:12.785345Z",
     "start_time": "2024-04-27T10:39:05.117365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#实时信息提问\n",
    "agent_executor.invoke({\"input\": \"北京今天的天气如何?\"})"
   ],
   "id": "af3fc51474eef8cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `search` with `{'query': '北京今天的天气'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'type': 'weather_result', 'temperature': '72', 'unit': 'Fahrenheit', 'precipitation': '20%', 'humidity': '55%', 'wind': '4 mph', 'location': '中国北京市', 'date': 'Saturday', 'weather': 'Cloudy'}\u001B[0m\u001B[32;1m\u001B[1;3m北京今天的天气是多云的，温度为72华氏度，降水概率为20%，湿度为55%，风速为4英里/小时。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '北京今天的天气如何?',\n",
       " 'output': '北京今天的天气是多云的，温度为72华氏度，降水概率为20%，湿度为55%，风速为4英里/小时。'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:40:12.646902Z",
     "start_time": "2024-04-27T10:40:04.567277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#前面的交互都不带记忆\n",
    "agent_executor.invoke({\"input\": \"截止目前我们都聊了什么?\"})"
   ],
   "id": "ef1259e2d4eae142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m对不起，我无法回答这个问题，因为我没有能力回顾我们之前的对话。我是一个基于AI的助手，我只能回答你当前的问题或者提供你需要的信息。如果你有任何问题，欢迎随时向我提问。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '截止目前我们都聊了什么?',\n",
       " 'output': '对不起，我无法回答这个问题，因为我没有能力回顾我们之前的对话。我是一个基于AI的助手，我只能回答你当前的问题或者提供你需要的信息。如果你有任何问题，欢迎随时向我提问。'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 添加记忆",
   "id": "6b5fc5cd2e2f8298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:41:21.590747Z",
     "start_time": "2024-04-27T10:41:14.234967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#交互时添加记忆\n",
    "agent_executor.invoke({\"input\": \"hi! 我叫bob\", \"chat_history\": []})"
   ],
   "id": "607154709c797a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你好，Bob！很高兴认识你。有什么我可以帮助你的吗？\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! 我叫bob',\n",
       " 'chat_history': [],\n",
       " 'output': '你好，Bob！很高兴认识你。有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:41:31.219817Z",
     "start_time": "2024-04-27T10:41:28.211793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#手动构造记忆数据\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! 我叫bob\"),\n",
    "            AIMessage(content=\"你好，Bob！很高兴认识你。有什么我可以帮助你的吗？\"),\n",
    "        ],\n",
    "        \"input\": \"我叫什么名字?\",\n",
    "    }\n",
    ")"
   ],
   "id": "adbf255d3754273d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你的名字是Bob。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! 我叫bob'),\n",
       "  AIMessage(content='你好，Bob！很高兴认识你。有什么我可以帮助你的吗？')],\n",
       " 'input': '我叫什么名字?',\n",
       " 'output': '你的名字是Bob。'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:41:56.777888Z",
     "start_time": "2024-04-27T10:41:56.768905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#使用RunnableWithMessageHistory自动构造记忆数据\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# 历史记录会存储在内存中\n",
    "message_history = ChatMessageHistory()\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ],
   "id": "c34257c903b72fd1",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:42:08.693318Z",
     "start_time": "2024-04-27T10:42:05.512596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! 我是tomie\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ],
   "id": "72fc7ed265bc29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你好，Tomie！很高兴见到你。有什么我可以帮助你的吗？\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! 我是tomie',\n",
       " 'chat_history': [],\n",
       " 'output': '你好，Tomie！很高兴见到你。有什么我可以帮助你的吗？'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:42:16.340870Z",
     "start_time": "2024-04-27T10:42:14.634113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"我叫什么名字?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ],
   "id": "36b66b21a5ebd833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你的名字是Tomie。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我叫什么名字?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好，Tomie！很高兴见到你。有什么我可以帮助你的吗？')],\n",
       " 'output': '你的名字是Tomie。'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:42:53.908800Z",
     "start_time": "2024-04-27T10:42:33.985324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"LangSmith如何使用?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ],
   "id": "880fdbe2bd58a512",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': '如何使用LangSmith'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mLangSmith User Guide | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we‚Äôll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they‚Äôre just starting their journey.Prototyping‚ÄãPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\n",
      "The ability to rapidly understand how the model is performing ‚Äî and debug where it is failing ‚Äî is incredibly important for this phase.Debugging‚ÄãWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\n",
      "\n",
      "These test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View‚ÄãWhen prototyping different versions of your applications and making changes, it‚Äôs important to see whether or not you‚Äôve regressed with respect to your initial test cases.\n",
      "Oftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\n",
      "In order to get a sense for which variant is performing better, it‚Äôs useful to be able to view results for different configurations on the same datapoints side-by-side. We‚Äôve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground‚ÄãLangSmith provides a playground environment for rapid iteration and experimentation.\n",
      "\n",
      "Oftentimes, it isn‚Äôt necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it‚Äôs extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\n",
      "We provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set‚ÄãWhile many developers still ship an initial version of their application based on ‚Äúvibe checks‚Äù, we‚Äôve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\u001B[0m\u001B[32;1m\u001B[1;3mLangSmith是一个用于LLM应用开发、监控和测试的平台。以下是一些主要的使用方式：\n",
      "\n",
      "1. **原型设计**：LangSmith支持快速实验，包括提示、模型类型、检索策略和其他参数。这对于理解模型的性能并调试其失败的地方非常重要。\n",
      "\n",
      "2. **调试**：在开发新的LLM应用时，我们建议默认启用LangSmith跟踪。\n",
      "\n",
      "3. **评估**：LangSmith允许开发者创建数据集，这些数据集是输入和参考输出的集合，可以用来对LLM应用进行测试。\n",
      "\n",
      "4. **比较视图**：当你在原型设计不同版本的应用并进行更改时，比较视图可以帮助你看到是否对初始测试用例产生了回归。\n",
      "\n",
      "5. **游乐场**：LangSmith提供了一个游乐场环境，用于快速迭代和实验。\n",
      "\n",
      "6. **生产监控和自动化**：LangSmith提供了清晰的可见性和每个LLM序列步骤的调试信息，使得识别和找出问题的根源变得更加容易。\n",
      "\n",
      "以上就是LangSmith的一些主要使用方式，希望对你有所帮助。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith如何使用?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好，Tomie！很高兴见到你。有什么我可以帮助你的吗？'),\n",
       "  HumanMessage(content='我叫什么名字?'),\n",
       "  AIMessage(content='你的名字是Tomie。')],\n",
       " 'output': 'LangSmith是一个用于LLM应用开发、监控和测试的平台。以下是一些主要的使用方式：\\n\\n1. **原型设计**：LangSmith支持快速实验，包括提示、模型类型、检索策略和其他参数。这对于理解模型的性能并调试其失败的地方非常重要。\\n\\n2. **调试**：在开发新的LLM应用时，我们建议默认启用LangSmith跟踪。\\n\\n3. **评估**：LangSmith允许开发者创建数据集，这些数据集是输入和参考输出的集合，可以用来对LLM应用进行测试。\\n\\n4. **比较视图**：当你在原型设计不同版本的应用并进行更改时，比较视图可以帮助你看到是否对初始测试用例产生了回归。\\n\\n5. **游乐场**：LangSmith提供了一个游乐场环境，用于快速迭代和实验。\\n\\n6. **生产监控和自动化**：LangSmith提供了清晰的可见性和每个LLM序列步骤的调试信息，使得识别和找出问题的根源变得更加容易。\\n\\n以上就是LangSmith的一些主要使用方式，希望对你有所帮助。'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:43:09.159432Z",
     "start_time": "2024-04-27T10:43:03.911747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#调用方式\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"截止目前我们都聊了什么?\"},\n",
    "    #注意此处session_id没有用到，因为我们没用类似redis的存储,只是用了一个变量\n",
    "    config={\"configurable\": {\"session_id\": \"foo_001\"}},\n",
    ")"
   ],
   "id": "82d5a9a339fe9c28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m我们的对话如下：\n",
      "\n",
      "1. 你向我介绍了你的名字，你叫Tomie。\n",
      "2. 我确认了你的名字是Tomie。\n",
      "3. 你询问了如何使用LangSmith。\n",
      "4. 我向你解释了LangSmith的主要使用方式，包括原型设计、调试、评估、比较视图、游乐场以及生产监控和自动化。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '截止目前我们都聊了什么?',\n",
       " 'chat_history': [HumanMessage(content='hi! 我是tomie'),\n",
       "  AIMessage(content='你好，Tomie！很高兴见到你。有什么我可以帮助你的吗？'),\n",
       "  HumanMessage(content='我叫什么名字?'),\n",
       "  AIMessage(content='你的名字是Tomie。'),\n",
       "  HumanMessage(content='LangSmith如何使用?'),\n",
       "  AIMessage(content='LangSmith是一个用于LLM应用开发、监控和测试的平台。以下是一些主要的使用方式：\\n\\n1. **原型设计**：LangSmith支持快速实验，包括提示、模型类型、检索策略和其他参数。这对于理解模型的性能并调试其失败的地方非常重要。\\n\\n2. **调试**：在开发新的LLM应用时，我们建议默认启用LangSmith跟踪。\\n\\n3. **评估**：LangSmith允许开发者创建数据集，这些数据集是输入和参考输出的集合，可以用来对LLM应用进行测试。\\n\\n4. **比较视图**：当你在原型设计不同版本的应用并进行更改时，比较视图可以帮助你看到是否对初始测试用例产生了回归。\\n\\n5. **游乐场**：LangSmith提供了一个游乐场环境，用于快速迭代和实验。\\n\\n6. **生产监控和自动化**：LangSmith提供了清晰的可见性和每个LLM序列步骤的调试信息，使得识别和找出问题的根源变得更加容易。\\n\\n以上就是LangSmith的一些主要使用方式，希望对你有所帮助。')],\n",
       " 'output': '我们的对话如下：\\n\\n1. 你向我介绍了你的名字，你叫Tomie。\\n2. 我确认了你的名字是Tomie。\\n3. 你询问了如何使用LangSmith。\\n4. 我向你解释了LangSmith的主要使用方式，包括原型设计、调试、评估、比较视图、游乐场以及生产监控和自动化。'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# agentType更新版",
   "id": "cea8199204def335"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![agtype.png](agtype.png)",
   "id": "bce15bccf5c209fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
