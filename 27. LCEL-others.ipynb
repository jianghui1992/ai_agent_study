{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T10:46:14.337355Z",
     "start_time": "2024-04-27T10:46:14.321368Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"openai.env\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 本地大模型调用",
   "id": "f7c89ce8b010f82c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:47:20.647568Z",
     "start_time": "2024-04-27T10:47:02.784275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2-chinese\")\n",
    "llm.invoke(input=\"你好啊\")"
   ],
   "id": "8b619ba651417bff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好啊，您是否需要我的帮助或提问呢？请告诉我您的疑问或需求。\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:50:10.875020Z",
     "start_time": "2024-04-27T10:50:07.547039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#使用流式\n",
    "for s in llm.stream(input=\"第一个登上月球的人是谁?只返回名字,不要返回其他信息\"):\n",
    "    print(s, end=\"\", flush=True)"
   ],
   "id": "bc0b89c47633ca4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尼尔·阿姆斯特朗（Neil Armstrong）"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型评估",
   "id": "e58dc31fc9992d1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:54:43.670403Z",
     "start_time": "2024-04-27T10:54:43.637524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain.evaluation import EvaluatorType\n",
    "\n",
    "llm = OpenAI()\n",
    "#内置标准：回答是否简明，criteria标准，conciseness简明度\n",
    "evaluator = load_evaluator(EvaluatorType.CRITERIA, llm=llm, criteria=\"conciseness\")"
   ],
   "id": "db37e3e411e80119",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:54:53.748687Z",
     "start_time": "2024-04-27T10:54:50.479941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# inpt 输入的评测问题\n",
    "# prediction 预测的答案\n",
    "# 返回值 Y/N 是否符合\n",
    "# 返回值score 1-0分数，1为完全符合，0为不完全符合\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    input=\"What's 2+2?\", prediction=\"four\"\n",
    ")\n",
    "print(eval_result)"
   ],
   "id": "e7884c8ff507ab4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'Step 1: Determine if the submission is concise and to the point.\\n- The submission is \"four\", which is a single word that clearly and directly answers the question \"What\\'s 2+2?\"\\n- It does not contain any unnecessary information or explanations.\\n- Therefore, the submission meets the criteria of conciseness.\\n\\nConclusion: The submission meets all criteria.\\n\\nY', 'value': 'Y', 'score': 1}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:56:50.629609Z",
     "start_time": "2024-04-27T10:56:47.343424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这个答案就明显不简洁,所以结果value=N, score=0\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    input=\"What's 2+2?\"\n",
    "    , prediction=\"What's 2+2? That's an elementary question. The answer you're looking for is that two and two is four.\"\n",
    ")\n",
    "print(eval_result)"
   ],
   "id": "ce6e6fda02eee8fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'Step 1: Evaluate the submission for conciseness.\\nThe submission is not concise as it includes unnecessary sentences and phrases such as \"That\\'s an elementary question\" and \"The answer you\\'re looking for is.\"\\n\\nStep 2: Determine if the submission meets the criteria.\\nBased on the evaluation in Step 1, the submission does not meet the criteria of conciseness.\\n\\nStep 3: Print the correct answer.\\nN', 'value': 'N', 'score': 0}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:59:11.669873Z",
     "start_time": "2024-04-27T10:58:51.861712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#需要评测的模型2 本地模型,可以看到,不同模型的标准不同,openai会更好一点\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama2-chinese\")\n",
    "evaluator = load_evaluator(EvaluatorType.CRITERIA, llm=llm, criteria=\"conciseness\")\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    input=\"What's 2+2?\",\n",
    "    prediction=\"What's 2+2? That's an elementary question. The answer you're looking for is that two and two is four.\",\n",
    ")\n",
    "print(eval_result)"
   ],
   "id": "25fff51a00c65cfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': \"2+2? That's an elementary question. The answer you're looking for is that two and two is four.\\nconciseness:\", 'value': 'Y', 'score': 1}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:59:11.677338Z",
     "start_time": "2024-04-27T10:59:11.671929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 内置的一些评估标准\n",
    "from langchain.evaluation import Criteria\n",
    "\n",
    "list(Criteria)"
   ],
   "id": "d26af490139c697e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Criteria.CONCISENESS: 'conciseness'>,\n",
       " <Criteria.RELEVANCE: 'relevance'>,\n",
       " <Criteria.CORRECTNESS: 'correctness'>,\n",
       " <Criteria.COHERENCE: 'coherence'>,\n",
       " <Criteria.HARMFULNESS: 'harmfulness'>,\n",
       " <Criteria.MALICIOUSNESS: 'maliciousness'>,\n",
       " <Criteria.HELPFULNESS: 'helpfulness'>,\n",
       " <Criteria.CONTROVERSIALITY: 'controversiality'>,\n",
       " <Criteria.MISOGYNY: 'misogyny'>,\n",
       " <Criteria.CRIMINALITY: 'criminality'>,\n",
       " <Criteria.INSENSITIVITY: 'insensitivity'>,\n",
       " <Criteria.DEPTH: 'depth'>,\n",
       " <Criteria.CREATIVITY: 'creativity'>,\n",
       " <Criteria.DETAIL: 'detail'>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 自定义评估标准",
   "id": "3acfa563c2431ef4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:01:24.540905Z",
     "start_time": "2024-04-27T11:01:21.152720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAI\n",
    "#使用enum格式加载标准\n",
    "from langchain.evaluation import EvaluatorType\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "#自定义评估标准\n",
    "custom_criterion = {\"幽默性\": \"输出的内容是否足够幽默或者包含幽默元素\", }\n",
    "eval_chain = load_evaluator(EvaluatorType.CRITERIA, llm=llm, criteria=custom_criterion, )\n",
    "query = \"给我讲一个笑话\"\n",
    "prediction = \"有一天，小明去买菜，结果买了一堆菜回家，结果发现自己忘了带钱。\"\n",
    "eval_result = eval_chain.evaluate_strings(prediction=prediction, input=query)\n",
    "print(eval_result)"
   ],
   "id": "b6af3d92b44cb4fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'Step 1: Identify the criteria\\nThe criteria given is \"幽默性\"\\n\\nStep 2: Analyze the submission\\nThe submission is a joke about a person forgetting to bring money while grocery shopping.\\n\\nStep 3: Evaluate the submission based on the criteria\\nThe submission includes a humorous situation of forgetting to bring money while shopping, which can be considered as a common and relatable experience. However, the submission does not have any specific humorous elements or punchline to make it stand out. Therefore, it may not meet the criteria of \"幽默性\" as it lacks a distinct humorous element.\\n\\nStep 4: Conclusion\\nBased on the analysis, it can be concluded that the submission does not meet the criteria of \"幽默性\".', 'value': 'Y', 'score': 1}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:03:04.529497Z",
     "start_time": "2024-04-27T11:01:51.632094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 可以看到llama2支持度不太好,没有理解任务\n",
    "llm = ChatOllama(model=\"llama2-chinese\")\n",
    "eval_chain = load_evaluator(EvaluatorType.CRITERIA, llm=llm, criteria=custom_criterion)\n",
    "eval_result = eval_chain.evaluate_strings(prediction=prediction, input=query)\n",
    "print(eval_result)"
   ],
   "id": "a6e0a0f5ebc07e6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': '1. 笑话内容是否足够幽默或者包含幽默元素。Y\\n2. 符合输入要求。Y\\n3. 有关优点和缺点的解释是否足够全面。N\\n4. 符合任务要求。Y\\n5. 不同于原始问题。N\\n6. 符合数据要求。Y\\n7. 可重复使用。Y\\n8. 适合输入的形式。Y\\n9. 符合提示要求。Y\\n10. 无需进一步检查。Y\\n\\n做完上述分析后，我们发现这个笑话具有足够的幽默性、符合输入要求和任务要求，且不用进一步解释优点和缺点，对于输入来说也符合数据要求、可重复使用以及适合输入的形式。因此我们可以确定这个笑话在上述参数下符合提示要求。\\n\\n为了保持编程的整潜力，只输出Y或N对应的字符串后一直等待终端中的任务完成。', 'value': '为了保持编程的整潜力，只输出Y或N对应的字符串后一直等待终端中的任务完成。', 'score': None}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型比较",
   "id": "25fff90e016ad25c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:04:34.686448Z",
     "start_time": "2024-04-27T11:04:25.273947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "#比较openai、ChatOllama二个模型的效果\n",
    "llms = [\n",
    "    OpenAI(temperature=0),\n",
    "    ChatOllama(model=\"llama2-chinese\"),\n",
    "]\n",
    "model_lab = ModelLaboratory.from_llms(llms)\n",
    "model_lab.compare(\"齐天大圣的师傅是谁？\")"
   ],
   "id": "b815758613ec752d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mInput:\u001B[0m\n",
      "齐天大圣的师傅是谁？\n",
      "\n",
      "\u001B[1mOpenAI\u001B[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256}\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "\n",
      "齐天大圣的师傅是菩提祖师。\u001B[0m\n",
      "\n",
      "model='llama2-chinese'\n",
      "\u001B[33;1m\u001B[1;3m\n",
      "答案：齐天大圣的师傅是卢伯契儿。\n",
      "\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:07:46.141509Z",
     "start_time": "2024-04-27T11:07:46.110130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"给我讲一个关于{topic}的笑话，控制在30个字之内\",\n",
    "    input_variables=[\"topic\"],\n",
    ")\n",
    "open_ai_llm = OpenAI(temperature=0)\n",
    "ollama_llm = ChatOllama(model=\"llama2-chinese\")\n",
    "openai_chain = LLMChain(llm=open_ai_llm, prompt=prompt, verbose=True)\n",
    "ollama_llm_chain = LLMChain(llm=ollama_llm, prompt=prompt, verbose=True)\n",
    "chains = [openai_chain, ollama_llm_chain]\n",
    "names = [str(open_ai_llm), str(ollama_llm_chain)]\n",
    "for name in names:\n",
    "    print(name)"
   ],
   "id": "de1ebd19c2ec5dc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mOpenAI\u001B[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256}\n",
      "verbose=True prompt=PromptTemplate(input_variables=['topic'], template='给我讲一个关于{topic}的笑话，控制在30个字之内') llm=ChatOllama(model='llama2-chinese')\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:08:42.568814Z",
     "start_time": "2024-04-27T11:08:21.236059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_lab = ModelLaboratory(chains, names=names)\n",
    "model_lab.compare(\"写作业\")"
   ],
   "id": "abb728d6edab374c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mInput:\u001B[0m\n",
      "写作业\n",
      "\n",
      "\u001B[1mOpenAI\u001B[0m\n",
      "Params: {'model_name': 'gpt-3.5-turbo-instruct', 'temperature': 0.0, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 256}\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m给我讲一个关于写作业的笑话，控制在30个字之内\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m\n",
      "\n",
      "老师问小明：为什么你的作业写得这么慢？小明回答：因为我是用手写的，不是用脑写的。\u001B[0m\n",
      "\n",
      "verbose=True prompt=PromptTemplate(input_variables=['topic'], template='给我讲一个关于{topic}的笑话，控制在30个字之内') llm=ChatOllama(model='llama2-chinese')\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m给我讲一个关于写作业的笑话，控制在30个字之内\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m为了提高他的写作技巧，小明去了一次写作课。教师问他：“你认为什么是最重要的事情？” 小明回答道：“我认为最重要的事情是早上好的餐子！”\n",
      "\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 调试-set_debug,set_verbose",
   "id": "eeba4783c0cd99ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:10:57.460893Z",
     "start_time": "2024-04-27T11:10:48.160723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#创建LLM \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "#定义工具,加载预制的工具,注意有的工具需要提供LLM\n",
    "from langchain.agents import load_tools\n",
    "#创建agent\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "#定义agent的执行器，这里注意与老版本的不同\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "#定义agent的prompt\n",
    "#https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ],
   "id": "12cae64187e99861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mHello! How can I assist you today?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:11:02.672657Z",
     "start_time": "2024-04-27T11:11:00.883283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "agent_executor.invoke({\"input\": \"你好啊！\"})"
   ],
   "id": "f1c9d1251a94c67e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"你好啊！\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"你好啊！\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"你好啊！\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: 你好啊！\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [1.76s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你好！有什么可以帮助你的吗？\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你好！有什么可以帮助你的吗？\",\n",
      "            \"example\": false,\n",
      "            \"additional_kwargs\": {},\n",
      "            \"tool_call_chunks\": [],\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"stop\"\n",
      "            },\n",
      "            \"id\": \"run-76cdb67e-b7af-45ca-80c1-6a679e1e16ea\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:OpenAIFunctionsAgentOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [1.77s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor] [1.78s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"你好！有什么可以帮助你的吗？\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好啊！', 'output': '你好！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T11:11:21.192449Z",
     "start_time": "2024-04-27T11:11:18.955716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.globals import set_verbose\n",
    "\n",
    "# 因为是全局生效,所以这里临时关闭一下,不影响set_verbose的效果\n",
    "set_debug(False)\n",
    "set_verbose(True)\n",
    "agent_executor.invoke({\"input\": \"你好啊！\"})"
   ],
   "id": "71860bd1e439f1a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m你好！有什么可以帮助你的吗？\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好啊！', 'output': '你好！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
