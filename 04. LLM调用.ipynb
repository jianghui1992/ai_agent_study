{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T05:44:11.728425Z",
     "start_time": "2024-04-27T05:44:11.725046Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_KEY\"] = \"sk-bQGeRZevfQI95TPb1b1a3e80011c4f368150270f687dF163\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://api.aihubmix.com/v1\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# OpenAI与ChatOpenAI\n",
    "- gpt3.5早期在langchain中叫openAI\n",
    "- chatgpt4.0后针对对话模型做了更多的优化适配,所以为了和之前的api区别,叫ChatOpenAI"
   ],
   "id": "b9863914fa15674d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OpenAI- LLM调用",
   "id": "f97e41d11d767aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T00:00:19.951383Z",
     "start_time": "2024-04-27T00:00:15.421186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLM的调用\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "llm.invoke(\"你好\")"
   ],
   "id": "61c45bd9f66a0675",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianghui/PycharmProjects/ai_agent_study/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'，我是小智，一个人工智能助手。我可以回答你的问题，帮助你解决问题，还可以和你聊天。有什么可以帮到你的吗？'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatOpenAI - chat models调用",
   "id": "406038a944ac857e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T05:47:30.082202Z",
     "start_time": "2024-04-27T05:47:23.143765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#调用chatmodels，以openai为例\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    # temperature为0表示结果灵活度为0, 结果固定, 当灵活度比较高时,大模型会有更丰富的回答,但是可能准确度不高\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# 可以直接调用对话\n",
    "print(chat.invoke(\"你好\"))\n",
    "\n",
    "# 也可以传递上下文,然后提问\n",
    "messages = [\n",
    "    AIMessage(role=\"system\", content=\"你好，我是tomie！\"),\n",
    "    HumanMessage(role=\"user\", content=\"你好tomie，我是狗剩!\"),\n",
    "    AIMessage(role=\"system\", content=\"认识你很高兴!\"),\n",
    "    HumanMessage(role=\"user\", content=\"你知道我叫什么吗？\")\n",
    "]\n",
    "print(chat.invoke(messages))"
   ],
   "id": "c5c20de8114c9fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好，有什么可以帮助你的吗？' response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 9, 'total_tokens': 26}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-b3ce2c83-52ef-47f5-9f70-af6fc13892b0-0'\n",
      "content='你刚刚告诉我，你的名字是狗剩。' response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 62, 'total_tokens': 83}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-e23139ea-74b5-48c2-9300-81325df2cb45-0'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# langchain内置的LLM支持情况",
   "id": "b03569d8eade5c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![LLMs](LLMs.png)",
   "id": "726f3c672735b998"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# stream 流式调用",
   "id": "ee3d15c1af1b61c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:53:47.808928Z",
     "start_time": "2024-04-18T13:53:41.883687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LLM类大模型的流式输出方法\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "#构造一个llm\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "for chunk in llm.stream(\"使用李白的风格,写一首关于秋天的诗歌\"):\n",
    "    print(chunk, end=\"\", flush=False)\n"
   ],
   "id": "8d87dc73d3c57264",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "秋风吹过黄叶飘，枫林红叶如火烧。\n",
      "天高云淡秋意浓，万木凋零似梦中。\n",
      "\n",
      "霜降寒气渐渐来，田野稻谷金色开。\n",
      "收获季节喜悦多，农人欢歌笑语中。\n",
      "\n",
      "秋雨绵绵润万物，山川湖海皆清澈。\n",
      "落叶飘零如诗意，思绪随风飘远去。\n",
      "\n",
      "秋天啊，你是多么美，给大地带来丰收喜。\n",
      "让人心中充满感激，感谢你带来的一切美。"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 追踪Token的使用: 花销控制",
   "id": "5cca5cb4ba15f622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:55:03.489349Z",
     "start_time": "2024-04-18T13:54:56.673313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LLM的token追踪\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "\n",
    "#构造一个llm\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"给我讲一个笑话\")\n",
    "    print(result)\n",
    "    print(cb)\n",
    "    # Tokens Used: 216  总token消耗\n",
    "    #     Prompt Tokens: 7   提示词的token消耗\n",
    "    #     Completion Tokens: 209  结果的token消耗"
   ],
   "id": "b3b4db38607a9e7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "有一天，小明去参加一个面试，面试官问他：“你有什么特长吗？”小明回答：“我可以用手指头数到100。”面试官觉得很奇怪，就让小明演示一下。小明开始用手指头数，数到10的时候，面试官就打断他说：“好了好了，我相信你了，你可以停下来了。”小明却不停地数，数到了100，面试官很惊讶地问：“你怎么能数到100？”小明回答：“因为我数到10的时候，我发现我的裤子拉链没拉上，我一边数一边拉上拉链，所以我就顺便数到了100。”\n",
      "Tokens Used: 216\n",
      "\tPrompt Tokens: 7\n",
      "\tCompletion Tokens: 209\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00042849999999999995\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 自定义输出\n",
    "- 输出函数参数\n",
    "- 输出json\n",
    "- 输出List\n",
    "- 输出日期"
   ],
   "id": "966c996a9e5b7f16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T14:12:27.628591Z",
     "start_time": "2024-04-19T14:12:24.089094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "! pip install --upgrade pydantic\n",
    "# ! pip install --upgrade langchain==0.1.16"
   ],
   "id": "1d9befcdbd7e3efd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.11/site-packages (1.10.15)\r\n",
      "Collecting pydantic\r\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/16/ca/330c4f3bd983bb24ac12c7fd1e08c26c8aed70bc64498cf38c770321067f/pydantic-2.7.0-py3-none-any.whl (407 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m407.9/407.9 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./venv/lib/python3.11/site-packages (from pydantic) (2.18.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.11/site-packages (from pydantic) (4.11.0)\r\n",
      "Installing collected packages: pydantic\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 1.10.15\r\n",
      "    Uninstalling pydantic-1.10.15:\r\n",
      "      Successfully uninstalled pydantic-1.10.15\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "doctran 0.0.14 requires openai<0.28.0,>=0.27.8, but you have openai 1.23.1 which is incompatible.\r\n",
      "doctran 0.0.14 requires pydantic<2.0.0,>=1.10.9, but you have pydantic 2.7.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed pydantic-2.7.0\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T14:13:54.796409Z",
     "start_time": "2024-04-19T14:13:54.759363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#讲笑话机器人：希望每次根据指令，可以输出一个这样的笑话(小明是怎么死的？笨死的)\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "# Pydantic 是python的一种数据模型\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "#构造LLM\n",
    "model = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "\n",
    "\n",
    "#定义1个Pydantic数据模型，用来描述最终的实例结构\n",
    "class Joke(BaseModel):\n",
    "    #setup和punchline应该是固定的字段\n",
    "    setup: str = Field(description=\"设置笑话的问题\")\n",
    "    punchline: str = Field(description=\"回答笑话的答案\")\n",
    "\n",
    "    #验证问题是否符合要求\n",
    "    @validator(\"setup\")\n",
    "    def question_check(cls, info):\n",
    "        # 如果question最后一个字符不是?,就抛出异常\n",
    "        if info[-1] != \"？\":\n",
    "            raise ValueError(\"不符合预期的问题格式\")\n",
    "        return info\n",
    "\n",
    "\n",
    "#将Joke数据模型传入\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的输入.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    # 输出格式渲染的设置参数\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "# | 管道符: prompt函数的输出传递给model函数的入参\n",
    "# 函数组合: 可以一次执行2个函数\n",
    "print(prompt.format(query=\"请给我讲一个笑话\"))"
   ],
   "id": "80d52b2fce761b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答用户的输入.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"description\": \"\\u8bbe\\u7f6e\\u7b11\\u8bdd\\u7684\\u95ee\\u9898\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"\\u56de\\u7b54\\u7b11\\u8bdd\\u7684\\u7b54\\u6848\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n",
      "请给我讲一个笑话\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cd/6gw212g16h3dr3bbgjtd725r0000gn/T/ipykernel_23374/1125580151.py:27: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.7/migration/\n",
      "  @validator(\"setup\")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:03:17.298123Z",
     "start_time": "2024-04-18T14:03:12.449401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_and_model = prompt | model\n",
    "out_put = prompt_and_model.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "print(\"out_put:\", out_put)\n",
    "parser.invoke(out_put)  # 针对返回的数据结构做校验"
   ],
   "id": "9aebefbc8ef6a6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_put: {\"setup\": \"为什么猫咪总是喜欢抓老鼠？\", \"punchline\": \"因为它们觉得老鼠是小弟弟！\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='为什么猫咪总是喜欢抓老鼠？', punchline='因为它们觉得老鼠是小弟弟！')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T14:07:33.782051Z",
     "start_time": "2024-04-18T14:07:31.173795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#LLM的输出格式化成python list形式，类似['a','b','c']\n",
    "\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "#构造LLM\n",
    "model = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_KEY\"),\n",
    "    openai_api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    ")\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"列出5个{subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "_input = prompt.format(subject=\"中国人名称\")\n",
    "output = model(_input)\n",
    "print(output)\n",
    "#格式化\n",
    "print(parser.parse(output))"
   ],
   "id": "bb144810e409dd8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "李明, 王芳, 张伟, 赵敏, 刘涛\n",
      "['李明', '王芳', '张伟', '赵敏', '刘涛']\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
